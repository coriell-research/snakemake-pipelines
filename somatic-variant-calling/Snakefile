import pandas as pd


configfile: "config.yaml"

WORK_DIR = "../data"
FASTP_OUT = f"{WORK_DIR}/fastp"
BWA_OUT = f"{WORK_DIR}/bwa"
MERGE_OUT = f"{WORK_DIR}/merge"
MARKDUP_OUT = f"{WORK_DIR}/markdup"
VARSCAN_PAIRED_OUT = f"{WORK_DIR}/varscan_paired"
MUSE_PAIRED_OUT = f"{WORK_DIR}/muse_paired"

# Define samples and experimental units
SAMPLES = pd.read_csv("samples.csv", sep=",", header=0)
UNITS = SAMPLES["PU"].tolist()

# Extract the PUs that need to be merged into single sample BAMs
PU_BY_SAMPLE = SAMPLES.groupby('SM')['PU'].agg(list).to_dict()

def get_replicates_for_merge(wildcards):
    units = PU_BY_SAMPLE[wildcards.sample]
    return [f"{BWA_OUT}/{u}.sorted.bam" for u in units]


# Extract a dictionary of tumor-normal pairs and single samples
PAIRED_SAMPLES = {}
SINGLE_SAMPLES = {}
for sample_name, group in SAMPLES.groupby("sample_name"):
    sample_id = str(sample_name)
    tumor_sms = group[group["tumor_normal"] == "tumor"]["SM"].unique()
    normal_sms = group[group["tumor_normal"] == "normal"]["SM"].unique()
    
    if len(tumor_sms) > 0:
        tumor_sm = tumor_sms[0]
        if len(normal_sms) > 0:
            normal_sm = normal_sms[0]
            PAIRED_SAMPLES[sample_id] = {"tumor": tumor_sm, "normal": normal_sm}
        else:
            SINGLE_SAMPLES[sample_id] = {"tumor": tumor_sm}


# Rules ----------------------------------------------------------------------


rule all:
    input:
        expand(f"{VARSCAN_PAIRED_OUT}/{{sample}}.snp.Somatic.hc.vcf", sample=PAIRED_SAMPLES.keys()),
        expand(f"{MUSE_PAIRED_OUT}/{{sample}}.vcf", sample=PAIRED_SAMPLES.keys())


rule fastp:
    input:
        r1 = lambda w: SAMPLES.loc[SAMPLES["PU"] == w.pu, "read1"].item(),
        r2 = lambda w: SAMPLES.loc[SAMPLES["PU"] == w.pu, "read2"].item()
    output:
        r1_out = temp(f"{FASTP_OUT}/{{pu}}.trimmed.1.fq.gz"),
        r2_out = temp(f"{FASTP_OUT}/{{pu}}.trimmed.2.fq.gz"),
        html = f"{FASTP_OUT}/{{pu}}.fastp.html",
        json = f"{FASTP_OUT}/{{pu}}.fastp.json"
    log:
        f"{FASTP_OUT}/{{pu}}_fastp.log"
    params:
        extra = config["fastp"]["extra_params"]
    shell:
        "fastp -i {input.r1} -I {input.r2} -o {output.r1_out} -O {output.r2_out} "
        "{params.extra} --html {output.html} --json {output.json} &> {log}"


rule bwa:
    input:
        r1 = f"{FASTP_OUT}/{{pu}}.trimmed.1.fq.gz",
        r2 = f"{FASTP_OUT}/{{pu}}.trimmed.2.fq.gz",
    output:
        bam = f"{BWA_OUT}/{{pu}}.sorted.bam",
        bai = f"{BWA_OUT}/{{pu}}.sorted.bam.bai"
    params:
         pid = lambda w: SAMPLES.loc[SAMPLES["PU"] == w.pu, "ID"].item(),
         sm = lambda w: SAMPLES.loc[SAMPLES["PU"] == w.pu, "SM"].item(),
         pl = lambda w: SAMPLES.loc[SAMPLES["PU"] == w.pu, "PL"].item(),
         lb = lambda w: SAMPLES.loc[SAMPLES["PU"] == w.pu, "LB"].item(),
         pu = lambda w: SAMPLES.loc[SAMPLES["PU"] == w.pu, "PU"].item(),
         idx = config["bwa"]["idx"],
         gb = 4
    threads:
        8
    log:
        f"{BWA_OUT}/{{pu}}.log"
    shell:
        """
        bwa mem -t {threads} -R '@RG\\tID:{params.pid}\\tSM:{params.sm}\\tPL:{params.pl}\\tLB:{params.lb}\\tPU:{params.pu}' {params.idx} {input.r1} {input.r2} | \
        samtools sort -@{threads} -m{params.gb}g -o {output.bam} - && samtools index {output.bam}
        """


rule merge_bam:
    input:
        get_replicates_for_merge
    output:
        f"{MERGE_OUT}/{{sample}}.bam"
    params:
        bams = lambda w, input: " ".join([f"-I {f}" for f in input]),
        java_args = config["java"]["java_args"]
    log:
        f"{MERGE_OUT}/{{sample}}.log"
    shell:
        "java {params.java_args} -jar /usr/local/programs/picard.jar MergeSamFiles "
          "{params} "
          "--OUTPUT {output} "
          "--ASSUME_SORTED true "
          "--CREATE_INDEX true "
          "--SORT_ORDER coordinate"


rule mark_duplicates:
    input:
        f"{MERGE_OUT}/{{sample}}.bam"
    output:
        bam = f"{MARKDUP_OUT}/{{sample}}.bam",
        metrics = f"{MARKDUP_OUT}/{{sample}}.metrics.txt"
    params:
        java_args = config["java"]["java_args"]
    log:
        f"{MARKDUP_OUT}/{{sample}}.log",
    shell:
        "java {params.java_args} -jar /usr/local/programs/picard.jar MarkDuplicates "
          "-I {input} "
          "-O {output.bam} "
          "-M {output.metrics} "
          "--ASSUME_SORT_ORDER coordinate "
          "--CREATE_INDEX true "


rule varscan_paired:
    input:
        tumor = lambda w: f"{MARKDUP_OUT}/{PAIRED_SAMPLES[str(w.sample)]['tumor']}.bam",
        normal = lambda w: f"{MARKDUP_OUT}/{PAIRED_SAMPLES[str(w.sample)]['normal']}.bam"
    output:
        snp_vcf = f"{VARSCAN_PAIRED_OUT}/{{sample}}.snp.vcf",
        indel_vcf = f"{VARSCAN_PAIRED_OUT}/{{sample}}.indel.vcf"
    log:
        f"{VARSCAN_PAIRED_OUT}/{{sample}}.somatic.log"
    params:
        ref = config["bwa"]["idx"],
        out_prefix = f"{VARSCAN_PAIRED_OUT}/{{sample}}"
    shell:
        """
        samtools mpileup \
            -d 10000 \
            -q 1 \
            -Q 30 \
            -f {params.ref} \
            {input.normal} {input.tumor} | \
        java -jar /usr/local/programs/VarScan.jar somatic \
            - \
            {params.out_prefix} \
            --mpileup 1 \
            --output-vcf 1 \
            --min-coverage 10 \
            --min-var-freq 0.05 \
            --somatic-p-value 0.05 \
            --output-snp {output.snp_vcf} \
            --output-indel {output.indel_vcf} \
            2> {log}
        """


rule varscan_filter_paired:
    input:
        snp_vcf = f"{VARSCAN_PAIRED_OUT}/{{sample}}.snp.vcf",
        indel_vcf = f"{VARSCAN_PAIRED_OUT}/{{sample}}.indel.vcf",
    output:
        vcf_filtered = f"{VARSCAN_PAIRED_OUT}/{{sample}}.snp.Somatic.hc.vcf"
    log:
        f"{VARSCAN_PAIRED_OUT}/{{sample}}.filter.log"
    params:
        min_cov = 10,
        min_reads = 4,
        min_strands = 1,
        min_var_freq = 0.05,
        p_value = 0.05
    shell:
        """
        java -jar /usr/local/programs/VarScan.jar somaticFilter \
            {input.snp_vcf} \
            --min-coverage {params.min_cov} \
            --min-reads2 {params.min_reads} \
            --min-strands2 {params.min_strands} \
            --min-var-freq {params.min_var_freq} \
            --p-value {params.p_value} \
            --indel-file {input.indel_vcf} \
            --output-file {output.vcf_filtered} \
            2> {log}
        """


rule muse_call_paired:
    input:
        tumor = lambda w: f"{MARKDUP_OUT}/{PAIRED_SAMPLES[str(w.sample)]['tumor']}.bam",
        normal = lambda w: f"{MARKDUP_OUT}/{PAIRED_SAMPLES[str(w.sample)]['normal']}.bam"
    output:
        txt = f"{MUSE_PAIRED_OUT}/{{sample}}.MuSE.txt"
    log:
        f"{MUSE_PAIRED_OUT}/{{sample}}.call.log"
    params:
        ref = config["bwa"]["idx"],
        out_prefix = f"{MUSE_PAIRED_OUT}/{{sample}}"
    threads: 4
    conda:
        "muse"
    shell:
        """
        MuSE call \
            -O {params.out_prefix} \
            -f {params.ref} \
            -n {threads} \
            {input.tumor} {input.normal} \
            2> {log}
        """


rule muse_sump_paired:
    input:
        txt = f"{MUSE_PAIRED_OUT}/{{sample}}.MuSE.txt"
    output:
        vcf = f"{MUSE_PAIRED_OUT}/{{sample}}.vcf"
    log:
        f"{MUSE_PAIRED_OUT}/{{sample}}.sump.log"
    params:
        dbsnp = config["muse"]["dbsnp"],
        mode = "-E"
    threads:
        4
    conda:
        "muse"
    shell:
        """
        MuSE sump \
            -I {input.txt} \
            {params.mode} \
            -n {threads} \
            -O {output.vcf} \
            -D {params.dbsnp} \
            2> {log}
        """